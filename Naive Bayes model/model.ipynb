{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text\n",
       "0     0  Go until jurong point, crazy.. Available only ...\n",
       "1     0                      Ok lar... Joking wif u oni...\n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     0  U dun say so early hor... U c already then say...\n",
       "4     0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_sms = pd.read_csv('sms_dataset.csv')\n",
    "dataframe_sms['spam'] = dataframe_sms['spam'].map({'spam': 1, 'ham': 0})\n",
    "dataframe_sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SMS: 5572\n",
      "Proportion of spam SMSs: 0.1341\n",
      "Proportion of ham SMSs: 0.8659\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of SMS: {len(dataframe_sms)}\")\n",
    "print(f\"Proportion of spam SMSs: {dataframe_sms.spam.sum()/len(dataframe_sms):.4f}\")\n",
    "print(f\"Proportion of ham SMSs: {1 - dataframe_sms.spam.sum()/len(dataframe_sms):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sms(df):\n",
    "    df = df.sample(frac = 1, ignore_index = True, random_state = 42)\n",
    "    X = df.text\n",
    "    Y = df.spam.to_numpy()\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = preprocess_sms(dataframe_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(X):\n",
    "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "    if isinstance(X, str):\n",
    "        X = np.array([X])\n",
    "\n",
    "    X_preprocessed = []\n",
    "    for i, sms in enumerate(X):\n",
    "        sms = np.array([i.lower() for i in word_tokenize(sms) if i.lower() not in stop]).astype(X.dtype)\n",
    "        X_preprocessed.append(sms)\n",
    "        \n",
    "    if len(X) == 1:\n",
    "        return X_preprocessed[0]\n",
    "    return X_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treated = preprocess_text(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(0.80*len(X_treated)) \n",
    "\n",
    "X_train = X_treated[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "X_test = X_treated[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of spam in train dataset: 0.1324\n",
      "Proportion of spam in test dataset: 0.1408\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of spam in train dataset: {sum(Y_train == 1)/len(Y_train):.4f}\")\n",
    "print(f\"Proportion of spam in test dataset: {sum(Y_test == 1)/len(Y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(X,Y):\n",
    "    word_dict = {}\n",
    "\n",
    "    num_sms = len(X)\n",
    "\n",
    "    for i in range(num_sms):\n",
    "        sms = X[i] \n",
    "        cls = Y[i] \n",
    "        sms = set(sms) \n",
    "\n",
    "        for word in sms:\n",
    "            if word not in word_dict.keys():\n",
    "                word_dict[word] = {\"spam\": 1, \"ham\": 1}\n",
    "\n",
    "            if cls == 0:    \n",
    "                word_dict[word][\"ham\"] += 1\n",
    "            if cls == 1:\n",
    "                word_dict[word][\"spam\"] += 1\n",
    "\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency = get_word_frequency(X_train,Y_train)\n",
    "class_frequency = {'ham': sum(Y_train == 0), 'spam': sum(Y_train == 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of spam SMS in training is: 0.1324\n",
      "The proportion of ham SMS in training is: 0.8676\n"
     ]
    }
   ],
   "source": [
    "proportion_spam = class_frequency['spam']/(class_frequency['ham'] + class_frequency['spam'])\n",
    "print(f\"The proportion of spam SMS in training is: {proportion_spam:.4f}\")\n",
    "print(f\"The proportion of ham SMS in training is: {1 - proportion_spam:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_word_given_class(word, cls, word_frequency, class_frequency):\n",
    "    amount_word_and_class = word_frequency[word][cls]\n",
    "    p_word_given_class = amount_word_and_class/class_frequency[cls]\n",
    "\n",
    "    return p_word_given_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sms_given_class(treated_sms, cls, word_frequency, class_frequency):\n",
    "    prob = 1\n",
    "\n",
    "    for word in treated_sms:\n",
    "        if word in word_frequency.keys(): \n",
    "            prob *= prob_word_given_class(word, cls, word_frequency, class_frequency)\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_sms_given_class(treated_sms, cls, word_frequency, class_frequency):\n",
    "    prob = 0\n",
    "\n",
    "    for word in treated_sms: \n",
    "        if word in word_frequency.keys(): \n",
    "            prob += np.log(prob_word_given_class(word, cls,word_frequency, class_frequency))\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_naive_bayes(treated_sms, word_frequency, class_frequency, return_likelihood = False):    \n",
    "    log_prob_sms_given_spam = log_prob_sms_given_class(treated_sms, cls = 'spam',word_frequency = word_frequency, class_frequency = class_frequency) \n",
    "    log_prob_sms_given_ham = log_prob_sms_given_class(treated_sms, cls = 'ham',word_frequency = word_frequency, class_frequency = class_frequency) \n",
    "\n",
    "    p_spam = class_frequency['spam']/(class_frequency['ham'] + class_frequency['spam']) \n",
    "    p_ham = class_frequency['ham']/(class_frequency['ham'] + class_frequency['spam']) \n",
    "\n",
    "    log_spam_likelihood = np.log(p_spam) + log_prob_sms_given_spam \n",
    "    log_ham_likelihood = np.log(p_ham) + log_prob_sms_given_ham \n",
    "\n",
    "    if return_likelihood == True:\n",
    "        return (log_spam_likelihood, log_ham_likelihood)\n",
    "\n",
    "    if log_spam_likelihood >= log_ham_likelihood:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_positives(Y_true, Y_pred):\n",
    "    if len(Y_true) != len(Y_pred):\n",
    "        return \"Number of true labels and predict labels must match!\"\n",
    "    n = len(Y_true)\n",
    "    true_positives = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        true_label_i = Y_true[i]\n",
    "        predicted_label_i = Y_pred[i]\n",
    "\n",
    "        if true_label_i == 1 and predicted_label_i == 1:\n",
    "            true_positives += 1\n",
    "    return true_positives\n",
    "        \n",
    "def get_true_negatives(Y_true, Y_pred):\n",
    "    if len(Y_true) != len(Y_pred):\n",
    "        return \"Number of true labels and predict labels must match!\"\n",
    "    n = len(Y_true)\n",
    "    true_negatives = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        true_label_i = Y_true[i]\n",
    "        predicted_label_i = Y_pred[i]\n",
    "        \n",
    "        if true_label_i == 0 and predicted_label_i == 0:\n",
    "            true_negatives += 1\n",
    "    return true_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test and Y_pred matches in length? Answer: True\n"
     ]
    }
   ],
   "source": [
    "Y_pred = []\n",
    "\n",
    "for sms in X_test:\n",
    "    prediction = log_naive_bayes(sms, word_frequency, class_frequency)\n",
    "    Y_pred.append(prediction)\n",
    "\n",
    "print(f\"Y_test and Y_pred matches in length? Answer: {len(Y_pred) == len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true positives is: 155\n",
      "The number of true negatives is: 831\n",
      "Accuracy is: 0.8843\n"
     ]
    }
   ],
   "source": [
    "true_positives = get_true_positives(Y_test, Y_pred)\n",
    "true_negatives = get_true_negatives(Y_test, Y_pred)\n",
    "print(f\"The number of true positives is: {true_positives}\\nThe number of true negatives is: {true_negatives}\")\n",
    "accuracy = (true_positives + true_negatives)/len(Y_test)\n",
    "print(f\"Accuracy is: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('parameters.pkl', 'wb') as f:\n",
    "    pickle.dump((word_frequency, class_frequency), f)\n",
    "\n",
    "## Here's how to load these parameters as variables\n",
    "\n",
    "with open('parameters.pkl', 'rb') as f:\n",
    "    word_frequency, class_frequency = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
